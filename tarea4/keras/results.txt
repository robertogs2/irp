Experimento_1 learning rates

Capas:
Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(10, activation='softmax')

Función de pérdida: 'categorical_crossentropy'
Métricas: 'accuracy' 

Épocas=25
Tamaño de minilote=32
Set de validación de 0.3 de datos de entrenamiento

Optimizador: Adam (lr=0.001)
Resultados:

Loss: 0.14882155562583502
Accuracy: 0.9624000191688538

CONFUSION MATRIX
[[ 957    0    0    1    5    5    2    2    3    5]
 [   0 1126    0    2    1    2    1    0    3    0]
 [   6    3  984   13    9    0    3    5    7    2]
 [   0    2    3  970    0   12    0    7    3   13]
 [   0    0    2    0  975    0    4    0    1    0]
 [   3    1    0   15    3  857    2    1    3    7]
 [   2    3    2    2    7   16  916    0   10    0]
 [   2   11    9    4   11    2    1  968    2   18]
 [   4    2    0   11    7    5    1    3  932    9]
 [   2    3    1    2   57    2    0    2    1  939]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.98      0.99      0.99      1135
           2       0.98      0.95      0.97      1032
           3       0.95      0.96      0.96      1010
           4       0.91      0.99      0.95       982
           5       0.95      0.96      0.96       892
           6       0.98      0.96      0.97       958
           7       0.98      0.94      0.96      1028
           8       0.97      0.96      0.96       974
           9       0.95      0.93      0.94      1009

    accuracy                           0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Optimizador: Adam (lr=0.005)

Loss: 0.23736964977955213
Accuracy: 0.9455999732017517

CONFUSION MATRIX
[[ 960    0    4    0    0    1    6    1    4    4]
 [   0 1116    3    4    1    2    3    0    6    0]
 [   3    5  981   13    9    1   10    5    5    0]
 [   3    1   17  921    0   43    2    5   12    6]
 [   1    0    3    0  930    0    8    2    7   31]
 [  12    0    9   11    3  817   25    4    9    2]
 [   4    2    2    0    6    7  932    0    5    0]
 [   1    8   27   10    2    4    1  957    5   13]
 [  10    3    9   15    9   16    7    3  901    1]
 [   4    4    4    7   14    9    1   13   12  941]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.95      0.94      1032
           3       0.94      0.91      0.93      1010
           4       0.95      0.95      0.95       982
           5       0.91      0.92      0.91       892
           6       0.94      0.97      0.95       958
           7       0.97      0.93      0.95      1028
           8       0.93      0.93      0.93       974
           9       0.94      0.93      0.94      1009

    accuracy                           0.95     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.95      0.95      0.95     10000

Optimizador: Adam (lr=0.01)

Loss: 0.26115881494851784
Accuracy: 0.9379000067710876

CONFUSION MATRIX
[[ 964    0    0    3    1    3    2    1    5    1]
 [   0 1108    5    8    0    1    2    4    7    0]
 [   9    0  977   11    8    2    2   15    8    0]
 [   4    0   30  910    0   22    1   20   13   10]
 [   2    1   12    3  924    0    1    1    2   36]
 [   8    1    3   37    2  788   12    4   26   11]
 [  13    1   45    4   10    3  875    0    5    2]
 [   3    7   11    6    4    5    0  981    0   11]
 [   7    2    8   19    5    7    3   11  900   12]
 [   6    4    1   10   11    8    1   10    6  952]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.95      0.98      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.89      0.95      0.92      1032
           3       0.90      0.90      0.90      1010
           4       0.96      0.94      0.95       982
           5       0.94      0.88      0.91       892
           6       0.97      0.91      0.94       958
           7       0.94      0.95      0.95      1028
           8       0.93      0.92      0.92       974
           9       0.92      0.94      0.93      1009

    accuracy                           0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000

Experimento_2 batch size

Capas:
Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(10, activation='softmax')

Optimizador: Adam (lr=0.001)
Función de pérdida: 'categorical_crossentropy'
Métricas: 'accuracy' 

Épocas=25
Set de validación de 0.3 de datos de entrenamiento

Resultados:

Tamaño de minilote=64

Loss: 0.1097333158312249
Accuracy: 0.9714999794960022

CONFUSION MATRIX
[[ 964    0    2    1    1    5    3    1    1    2]
 [   0 1125    1    3    0    0    0    2    4    0]
 [   2    0 1005    7    3    0    2    7    6    0]
 [   0    0    4  991    0    2    0    5    2    6]
 [   1    2    4    1  949    3    3    2    0   17]
 [   5    0    0   10    1  865    5    1    3    2]
 [   4    3    2    1   16    9  919    0    3    1]
 [   2    6    9    3    1    0    0  985    3   19]
 [   7    0    4   10    5    5    1    4  933    5]
 [   2    2    1    3   11    6    1    2    2  979]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.96      0.98      0.97      1010
           4       0.96      0.97      0.96       982
           5       0.97      0.97      0.97       892
           6       0.98      0.96      0.97       958
           7       0.98      0.96      0.97      1028
           8       0.97      0.96      0.97       974
           9       0.95      0.97      0.96      1009

    accuracy                           0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000

Tamaño de minilote=128

Loss: 0.12393855071500293
Accuracy: 0.96670001745224

CONFUSION MATRIX
[[ 962    0    6    3    0    2    2    2    1    2]
 [   0 1122    6    1    0    2    1    1    2    0]
 [   1    0 1022    4    0    0    0    4    1    0]
 [   2    0   15  982    0    5    0    2    3    1]
 [   2    1    7    2  929    3    5    7    5   21]
 [   4    0    0   22    0  845    9    0    9    3]
 [   6    3    7    1    2    2  935    0    2    0]
 [   1    4   25    9    0    0    0  983    2    4]
 [   3    0    7   10    1    4    1    6  942    0]
 [   3    3    1   20    7    6    1   12   11  945]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.93      0.99      0.96      1032
           3       0.93      0.97      0.95      1010
           4       0.99      0.95      0.97       982
           5       0.97      0.95      0.96       892
           6       0.98      0.98      0.98       958
           7       0.97      0.96      0.96      1028
           8       0.96      0.97      0.97       974
           9       0.97      0.94      0.95      1009

    accuracy                           0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000

Tamaño de minilote=16

Loss: 0.15071250206338072
Accuracy: 0.9692999720573425

CONFUSION MATRIX
[[ 963    1    2    0    0    4    1    3    2    4]
 [   0 1121    4    1    0    0    6    1    2    0]
 [   2    0 1008    2    4    1    0    9    6    0]
 [   1    0   11  958    0    6    0   12   16    6]
 [   1    0    3    0  961    0    2    4    2    9]
 [   2    0    0   14    1  847   13    2    7    6]
 [   5    2    1    1    5    4  937    0    2    1]
 [   1    6   14    2    3    0    0  991    5    6]
 [   3    0    7    2    3    3    1    3  948    4]
 [   1    4    2    5   19    4    2    7    6  959]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.98      0.97      1032
           3       0.97      0.95      0.96      1010
           4       0.96      0.98      0.97       982
           5       0.97      0.95      0.96       892
           6       0.97      0.98      0.98       958
           7       0.96      0.96      0.96      1028
           8       0.95      0.97      0.96       974
           9       0.96      0.95      0.96      1009

    accuracy                           0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Experimento_2 epochs

Capas:
Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(10, activation='softmax')

Optimizador: Adam (lr=0.001)
Función de pérdida: 'categorical_crossentropy'
Métricas: 'accuracy' 

Tamaño de minilote=64
Set de validación de 0.3 de datos de entrenamiento

Resultados:

Épocas=50

Loss: 0.14706791637024982
Accuracy: 0.972599983215332

CONFUSION MATRIX
[[ 966    1    2    1    0    1    6    1    2    0]
 [   0 1122    3    1    0    2    3    2    2    0]
 [   2    2 1005    6    0    0    6    8    3    0]
 [   1    2    5  971    0   11    0    7    8    5]
 [   2    2    1    1  946    0    7    6    3   14]
 [   2    0    0    8    0  857   12    3    8    2]
 [   7    2    0    0    4    5  936    1    3    0]
 [   0    3    8    2    0    1    0 1011    3    0]
 [   1    0    2    7    3    3    3    5  948    2]
 [   3    4    0    7    4    5    1   10   11  964]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.97      0.98      1032
           3       0.97      0.96      0.96      1010
           4       0.99      0.96      0.98       982
           5       0.97      0.96      0.96       892
           6       0.96      0.98      0.97       958
           7       0.96      0.98      0.97      1028
           8       0.96      0.97      0.96       974
           9       0.98      0.96      0.97      1009

    accuracy                           0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000

Épocas = 100
