Experimento_1 learning rates

Capas:
Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(10, activation='softmax')

Función de pérdida: 'categorical_crossentropy'
Métricas: 'accuracy' 

Épocas=25
Tamaño de minilote=32
Set de validación de 0.3 de datos de entrenamiento

Optimizador: Adam (lr=0.001)
Resultados:

Loss: 0.14882155562583502
Accuracy: 0.9624000191688538

CONFUSION MATRIX
[[ 957    0    0    1    5    5    2    2    3    5]
 [   0 1126    0    2    1    2    1    0    3    0]
 [   6    3  984   13    9    0    3    5    7    2]
 [   0    2    3  970    0   12    0    7    3   13]
 [   0    0    2    0  975    0    4    0    1    0]
 [   3    1    0   15    3  857    2    1    3    7]
 [   2    3    2    2    7   16  916    0   10    0]
 [   2   11    9    4   11    2    1  968    2   18]
 [   4    2    0   11    7    5    1    3  932    9]
 [   2    3    1    2   57    2    0    2    1  939]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.98      0.99      0.99      1135
           2       0.98      0.95      0.97      1032
           3       0.95      0.96      0.96      1010
           4       0.91      0.99      0.95       982
           5       0.95      0.96      0.96       892
           6       0.98      0.96      0.97       958
           7       0.98      0.94      0.96      1028
           8       0.97      0.96      0.96       974
           9       0.95      0.93      0.94      1009

    accuracy                           0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Optimizador: Adam (lr=0.005)

Loss: 0.23736964977955213
Accuracy: 0.9455999732017517

CONFUSION MATRIX
[[ 960    0    4    0    0    1    6    1    4    4]
 [   0 1116    3    4    1    2    3    0    6    0]
 [   3    5  981   13    9    1   10    5    5    0]
 [   3    1   17  921    0   43    2    5   12    6]
 [   1    0    3    0  930    0    8    2    7   31]
 [  12    0    9   11    3  817   25    4    9    2]
 [   4    2    2    0    6    7  932    0    5    0]
 [   1    8   27   10    2    4    1  957    5   13]
 [  10    3    9   15    9   16    7    3  901    1]
 [   4    4    4    7   14    9    1   13   12  941]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.95      0.94      1032
           3       0.94      0.91      0.93      1010
           4       0.95      0.95      0.95       982
           5       0.91      0.92      0.91       892
           6       0.94      0.97      0.95       958
           7       0.97      0.93      0.95      1028
           8       0.93      0.93      0.93       974
           9       0.94      0.93      0.94      1009

    accuracy                           0.95     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.95      0.95      0.95     10000

Optimizador: Adam (lr=0.01)

Loss: 0.26115881494851784
Accuracy: 0.9379000067710876

CONFUSION MATRIX
[[ 964    0    0    3    1    3    2    1    5    1]
 [   0 1108    5    8    0    1    2    4    7    0]
 [   9    0  977   11    8    2    2   15    8    0]
 [   4    0   30  910    0   22    1   20   13   10]
 [   2    1   12    3  924    0    1    1    2   36]
 [   8    1    3   37    2  788   12    4   26   11]
 [  13    1   45    4   10    3  875    0    5    2]
 [   3    7   11    6    4    5    0  981    0   11]
 [   7    2    8   19    5    7    3   11  900   12]
 [   6    4    1   10   11    8    1   10    6  952]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.95      0.98      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.89      0.95      0.92      1032
           3       0.90      0.90      0.90      1010
           4       0.96      0.94      0.95       982
           5       0.94      0.88      0.91       892
           6       0.97      0.91      0.94       958
           7       0.94      0.95      0.95      1028
           8       0.93      0.92      0.92       974
           9       0.92      0.94      0.93      1009

    accuracy                           0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000

Experimento_2 batch size

Capas:
Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(10, activation='softmax')

Optimizador: Adam (lr=0.001)
Función de pérdida: 'categorical_crossentropy'
Métricas: 'accuracy' 

Épocas=25
Set de validación de 0.3 de datos de entrenamiento

Resultados:

Tamaño de minilote=64

Loss: 0.1097333158312249
Accuracy: 0.9714999794960022

CONFUSION MATRIX
[[ 964    0    2    1    1    5    3    1    1    2]
 [   0 1125    1    3    0    0    0    2    4    0]
 [   2    0 1005    7    3    0    2    7    6    0]
 [   0    0    4  991    0    2    0    5    2    6]
 [   1    2    4    1  949    3    3    2    0   17]
 [   5    0    0   10    1  865    5    1    3    2]
 [   4    3    2    1   16    9  919    0    3    1]
 [   2    6    9    3    1    0    0  985    3   19]
 [   7    0    4   10    5    5    1    4  933    5]
 [   2    2    1    3   11    6    1    2    2  979]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.96      0.98      0.97      1010
           4       0.96      0.97      0.96       982
           5       0.97      0.97      0.97       892
           6       0.98      0.96      0.97       958
           7       0.98      0.96      0.97      1028
           8       0.97      0.96      0.97       974
           9       0.95      0.97      0.96      1009

    accuracy                           0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000

Tamaño de minilote=128

Loss: 0.12393855071500293
Accuracy: 0.96670001745224

CONFUSION MATRIX
[[ 962    0    6    3    0    2    2    2    1    2]
 [   0 1122    6    1    0    2    1    1    2    0]
 [   1    0 1022    4    0    0    0    4    1    0]
 [   2    0   15  982    0    5    0    2    3    1]
 [   2    1    7    2  929    3    5    7    5   21]
 [   4    0    0   22    0  845    9    0    9    3]
 [   6    3    7    1    2    2  935    0    2    0]
 [   1    4   25    9    0    0    0  983    2    4]
 [   3    0    7   10    1    4    1    6  942    0]
 [   3    3    1   20    7    6    1   12   11  945]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.93      0.99      0.96      1032
           3       0.93      0.97      0.95      1010
           4       0.99      0.95      0.97       982
           5       0.97      0.95      0.96       892
           6       0.98      0.98      0.98       958
           7       0.97      0.96      0.96      1028
           8       0.96      0.97      0.97       974
           9       0.97      0.94      0.95      1009

    accuracy                           0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000

Tamaño de minilote=16

Loss: 0.15071250206338072
Accuracy: 0.9692999720573425

CONFUSION MATRIX
[[ 963    1    2    0    0    4    1    3    2    4]
 [   0 1121    4    1    0    0    6    1    2    0]
 [   2    0 1008    2    4    1    0    9    6    0]
 [   1    0   11  958    0    6    0   12   16    6]
 [   1    0    3    0  961    0    2    4    2    9]
 [   2    0    0   14    1  847   13    2    7    6]
 [   5    2    1    1    5    4  937    0    2    1]
 [   1    6   14    2    3    0    0  991    5    6]
 [   3    0    7    2    3    3    1    3  948    4]
 [   1    4    2    5   19    4    2    7    6  959]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.98      0.97      1032
           3       0.97      0.95      0.96      1010
           4       0.96      0.98      0.97       982
           5       0.97      0.95      0.96       892
           6       0.97      0.98      0.98       958
           7       0.96      0.96      0.96      1028
           8       0.95      0.97      0.96       974
           9       0.96      0.95      0.96      1009

    accuracy                           0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Experimento_3 epochs

Capas:
Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(10, activation='softmax')

Optimizador: Adam (lr=0.001)
Función de pérdida: 'categorical_crossentropy'
Métricas: 'accuracy' 

Tamaño de minilote=64
Set de validación de 0.3 de datos de entrenamiento

Resultados:

Épocas=50

Loss: 0.14706791637024982
Accuracy: 0.972599983215332

CONFUSION MATRIX
[[ 966    1    2    1    0    1    6    1    2    0]
 [   0 1122    3    1    0    2    3    2    2    0]
 [   2    2 1005    6    0    0    6    8    3    0]
 [   1    2    5  971    0   11    0    7    8    5]
 [   2    2    1    1  946    0    7    6    3   14]
 [   2    0    0    8    0  857   12    3    8    2]
 [   7    2    0    0    4    5  936    1    3    0]
 [   0    3    8    2    0    1    0 1011    3    0]
 [   1    0    2    7    3    3    3    5  948    2]
 [   3    4    0    7    4    5    1   10   11  964]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.97      0.98      1032
           3       0.97      0.96      0.96      1010
           4       0.99      0.96      0.98       982
           5       0.97      0.96      0.96       892
           6       0.96      0.98      0.97       958
           7       0.96      0.98      0.97      1028
           8       0.96      0.97      0.96       974
           9       0.98      0.96      0.97      1009

    accuracy                           0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000

Épocas = 100

Loss: 0.3135537715569669
Accuracy: 0.9629999995231628

[[ 972    1    1    0    0    1    2    2    0    1]
 [   0 1127    2    2    0    2    1    1    0    0]
 [   9    2  998   13    3    0    1    5    1    0]
 [   0    1   10  981    0   11    0    4    1    2]
 [   1    0    0    0  972    0    6    2    0    1]
 [   7    0    0   10    2  855   10    3    3    2]
 [   6    4    2    1    3    3  938    0    1    0]
 [   1    7   15    8    4    0    0  992    0    1]
 [  16    2   16   28   11   13   14    4  866    4]
 [   6    5    1   12   40    4    1    9    2  929]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.95      0.99      0.97       980
           1       0.98      0.99      0.99      1135
           2       0.96      0.97      0.96      1032
           3       0.93      0.97      0.95      1010
           4       0.94      0.99      0.96       982
           5       0.96      0.96      0.96       892
           6       0.96      0.98      0.97       958
           7       0.97      0.96      0.97      1028
           8       0.99      0.89      0.94       974
           9       0.99      0.92      0.95      1009

    accuracy                           0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000

Épocas=150

Loss: 0.268998896088013
Accuracy: 0.9724000096321106

CONFUSION MATRIX
[[ 968    0    0    0    0    1    2    0    5    4]
 [   1 1117    3    5    0    0    2    1    6    0]
 [   4    1 1004    5    3    0    5    4    5    1]
 [   2    0    5  978    0    4    0    4    5   12]
 [   0    0    3    0  951    0    2    4    0   22]
 [   7    0    0   18    2  840    6    2    4   13]
 [   5    2    0    0    6    5  939    0    1    0]
 [   0    2    6    1    2    0    0  995    6   16]
 [   5    0    6    6    4    1    0    2  940   10]
 [   2    2    0    5    5    0    0    3    0  992]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.98      0.99      1135
           2       0.98      0.97      0.98      1032
           3       0.96      0.97      0.96      1010
           4       0.98      0.97      0.97       982
           5       0.99      0.94      0.96       892
           6       0.98      0.98      0.98       958
           7       0.98      0.97      0.97      1028
           8       0.97      0.97      0.97       974
           9       0.93      0.98      0.95      1009

    accuracy                           0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Épocas=250

Loss: 0.3280120501362802
Accuracy: 0.9718000292778015

CONFUSION MATRIX
[[ 965    0    2    1    0    3    4    1    3    1]
 [   0 1130    0    0    0    1    1    0    3    0]
 [   4    2  996   12    1    1    1   10    5    0]
 [   0    1    6  981    0    5    0    9    5    3]
 [   2    0    2    0  944    0    6    2    1   25]
 [   3    2    0   16    2  850    6    1    7    5]
 [   3    4    2    0    2    7  933    1    6    0]
 [   1    7    4    5    0    1    0  999    3    8]
 [   0    1    1    9    6    4    4    3  943    3]
 [   4    1    1    7   10    4    1    1    3  977]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.98      1.00      0.99      1135
           2       0.98      0.97      0.97      1032
           3       0.95      0.97      0.96      1010
           4       0.98      0.96      0.97       982
           5       0.97      0.95      0.96       892
           6       0.98      0.97      0.97       958
           7       0.97      0.97      0.97      1028
           8       0.96      0.97      0.97       974
           9       0.96      0.97      0.96      1009

    accuracy                           0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Experimento_4 activation

Capas:
Dense(64, activation='sigmoid')
Dense(64, activation='sigmoid')
Dense(10, activation='softmax')

Optimizador: Adam (lr=0.001)
Función de pérdida: 'categorical_crossentropy'
Métricas: 'accuracy' 

Épocas=150
Tamaño de minilote=64
Set de validación de 0.3 de datos de entrenamiento

Resultados:

Loss: 0.16873575312942962
Accuracy: 0.9697999954223633

CONFUSION MATRIX
[[207   0   3 395  11 119   8   0  71 166]
 [  0   0   0 164   0   0   0   0 951  20]
 [  1   0 174 430  21   1   1   0 380  24]
 [  0   0   0 977   0   1   0   0  26   6]
 [  0   0   0  30 254   0   3   0 237 458]
 [  1   0   0 528   4 172   0   0  87 100]
 [  0   0  11 151 196   9  37   0 476  78]
 [  0   0   1 172   2   0   0  11  89 753]
 [  0   0   0  73   0   0   0   0 872  29]
 [  1   0   0  49   1   1   0   0  60 897]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.99      0.21      0.35       980
           1       0.00      0.00      0.00      1135
           2       0.92      0.17      0.29      1032
           3       0.33      0.97      0.49      1010
           4       0.52      0.26      0.35       982
           5       0.57      0.19      0.29       892
           6       0.76      0.04      0.07       958
           7       1.00      0.01      0.02      1028
           8       0.27      0.90      0.41       974
           9       0.35      0.89      0.51      1009

    accuracy                           0.36     10000
   macro avg       0.57      0.36      0.28     10000
weighted avg       0.56      0.36      0.27     10000


Dense(64, activation='sigmoid')
Dense(64, activation='relu')
Dense(10, activation='softmax')

Loss: 0.17788136443049507
Accuracy: 0.9728000164031982

CONFUSION MATRIX
[[ 706    0  138    2    7   57   31    0   20   19]
 [   0    7   97   23    0    1    2    0 1005    0]
 [   8    0  847   19   21    0   11    1  116    9]
 [  10    2   79  692    5   64    7    0  121   30]
 [   2    0   86    0  722    0   11    0  110   51]
 [  14    1  100   19   10  377   47    0  303   21]
 [  10    0  173    0   11   10  704    1   49    0]
 [   6    0  148  144   43    4    1  488   92  102]
 [   6    0   20    2    6    0    4    0  919   17]
 [   7    1   78    1   35    1    2    4  200  680]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.92      0.72      0.81       980
           1       0.64      0.01      0.01      1135
           2       0.48      0.82      0.61      1032
           3       0.77      0.69      0.72      1010
           4       0.84      0.74      0.78       982
           5       0.73      0.42      0.54       892
           6       0.86      0.73      0.79       958
           7       0.99      0.47      0.64      1028
           8       0.31      0.94      0.47       974
           9       0.73      0.67      0.70      1009

    accuracy                           0.61     10000
   macro avg       0.73      0.62      0.61     10000
weighted avg       0.73      0.61      0.60     10000

Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(10, activation='softmax')

Loss: 0.18575592479631264
Accuracy: 0.9765999913215637

CONFUSION MATRIX
[[ 970    0    2    0    0    3    3    1    1    0]
 [   0 1127    0    4    0    0    2    1    1    0]
 [   5    2 1011    5    1    0    4    3    0    1]
 [   0    1    6  982    0    8    0    3    3    7]
 [   1    0    4    0  946    0   10    1    1   19]
 [   3    0    0    8    1  865    6    2    4    3]
 [   4    4    0    1    3    3  943    0    0    0]
 [   0    5   11    3    0    1    0 1001    0    7]
 [   3    1    8    2    2    4    5    6  940    3]
 [   1    3    0    5    6    4    2    3    4  981]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.98      0.97      1032
           3       0.97      0.97      0.97      1010
           4       0.99      0.96      0.97       982
           5       0.97      0.97      0.97       892
           6       0.97      0.98      0.98       958
           7       0.98      0.97      0.98      1028
           8       0.99      0.97      0.98       974
           9       0.96      0.97      0.97      1009

    accuracy                           0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000

Dense(64, activation='relu', input_shape=(784,)),
Dropout(0.5),
Dense(64, activation='relu'),
Dropout(0.5),
Dense(10, activation='softmax')

Loss: 0.21226900997087358
Accuracy: 0.9391999840736389

CONFUSION MATRIX
[[ 954    0    2    1    1    5   12    2    3    0]
 [   0 1119    3    1    1    1    1    1    8    0]
 [   2    9  979    6    4    1    4   15   12    0]
 [   2    6   24  873    1   81    0   13    8    2]
 [   0    3    4    0  926    0   14    5    3   27]
 [   4    2    3    9    6  822   18    4   16    8]
 [   8    4    5    0    6    7  928    0    0    0]
 [   2   12   20    1    2    0    0  980    1   10]
 [   7   19    5    5    9   22    6   10  888    3]
 [   5    5    0    2   23   25    1   18    7  923]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.95      0.99      0.97      1135
           2       0.94      0.95      0.94      1032
           3       0.97      0.86      0.92      1010
           4       0.95      0.94      0.94       982
           5       0.85      0.92      0.89       892
           6       0.94      0.97      0.96       958
           7       0.94      0.95      0.94      1028
           8       0.94      0.91      0.92       974
           9       0.95      0.91      0.93      1009

    accuracy                           0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000
