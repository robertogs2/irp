Experimento_1 learning rates

Capas:
Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(10, activation='softmax')

Función de pérdida: 'categorical_crossentropy'
Métricas: 'accuracy' 

Épocas=25
Tamaño de minilote=32
Set de validación de 0.3 de datos de entrenamiento

Optimizador: Adam (lr=0.001)
Resultados:

Loss: 0.11587326319531567
Accuracy: 0.97079998254776


CONFUSION MATRIX
[[ 963    0    2    1    0    5    4    1    4    0]
 [   1 1114    3    1    3    1    2    1    8    1]
 [   5    0 1012    4    1    0    3    4    3    0]
 [   1    0    6  988    0    3    0    5    3    4]
 [   2    0    0    0  947    1   12    8    2   10]
 [   2    0    0   10    1  857    6    1    9    6]
 [   1    3    4    1    2    4  940    0    3    0]
 [   1    4    7    7    1    1    0  996    1   10]
 [   2    0    6   21    6    6    4    5  919    5]
 [   2    2    0    6   16    2    3    6    0  972]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.99      0.98      0.99      1135
           2       0.97      0.98      0.98      1032
           3       0.95      0.98      0.96      1010
           4       0.97      0.96      0.97       982
           5       0.97      0.96      0.97       892
           6       0.97      0.98      0.97       958
           7       0.97      0.97      0.97      1028
           8       0.97      0.94      0.95       974
           9       0.96      0.96      0.96      1009

    accuracy                           0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Optimizador: Adam (lr=0.005)

Loss: 0.19933087874373304
Accuracy: 0.9517999887466431


CONFUSION MATRIX
[[ 967    0    0    1    1    2    2    2    3    2]
 [   0 1105    3    3    2    1    3    0    9    9]
 [  10    3  977    9    3    1    3    9   16    1]
 [   1    0    7  924    0   11    0    3   10   54]
 [   1    0    5    0  938    0    5    1    0   32]
 [   5    1    0    9    1  844    5    3    9   15]
 [   5    3    4    1   12   14  907    1   11    0]
 [   1    2    7   15    2    1    0  964    5   31]
 [   2    1    4   13    4    8    3    2  905   32]
 [   4    0    0    1    8    1    0    3    5  987]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.97      0.98      1135
           2       0.97      0.95      0.96      1032
           3       0.95      0.91      0.93      1010
           4       0.97      0.96      0.96       982
           5       0.96      0.95      0.95       892
           6       0.98      0.95      0.96       958
           7       0.98      0.94      0.96      1028
           8       0.93      0.93      0.93       974
           9       0.85      0.98      0.91      1009

    accuracy                           0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000

Optimizador: Adam (lr=0.01)

Loss: 0.2806307187501341
Accuracy: 0.932699978351593

CONFUSION MATRIX
[[ 959    0    3    0    0    4    6    1    7    0]
 [   0 1103    5    5    0    4    2    3   12    1]
 [  10    1  970    1    8    5    8    9   19    1]
 [   3    2   33  905    1   22    1   15   28    0]
 [   0    2   10    0  914    3    9    1    7   36]
 [   9    1    3   33    1  796   10    4   25   10]
 [   9    3    6    0   11    8  912    0    9    0]
 [   0    5   23    0    8    7    0  966    7   12]
 [   7    7   17   16    6   10   11    7  888    5]
 [   4    2    1    8   32   11    0   15   22  914]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.97      0.98      1135
           2       0.91      0.94      0.92      1032
           3       0.93      0.90      0.92      1010
           4       0.93      0.93      0.93       982
           5       0.91      0.89      0.90       892
           6       0.95      0.95      0.95       958
           7       0.95      0.94      0.94      1028
           8       0.87      0.91      0.89       974
           9       0.93      0.91      0.92      1009

    accuracy                           0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000

Experimento_2 batch size

Capas:
Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(10, activation='softmax')

Optimizador: Adam (lr=0.001)
Función de pérdida: 'categorical_crossentropy'
Métricas: 'accuracy' 

Épocas=25
Set de validación de 0.3 de datos de entrenamiento

Resultados:

Tamaño de minilote=64

Loss: 0.11969113888424145
Accuracy: 0.9715999960899353


CONFUSION MATRIX
[[ 964    1    2    1    0    1    6    1    3    1]
 [   0 1125    2    1    0    1    4    1    1    0]
 [   4    2  998    4    2    4    1   12    5    0]
 [   1    3    5  975    0    3    1   13    7    2]
 [   0    0    5    0  956    0    5    1    1   14]
 [   5    2    1    7    0  854    9    2    7    5]
 [   4    3    2    0    2    2  942    0    3    0]
 [   0    9   13    1    0    0    1 1004    0    0]
 [   4    2    8   10    2    3    7    6  931    1]
 [   1    4    2    3   14    2    0   12    4  967]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.98      0.99      0.98      1135
           2       0.96      0.97      0.96      1032
           3       0.97      0.97      0.97      1010
           4       0.98      0.97      0.98       982
           5       0.98      0.96      0.97       892
           6       0.97      0.98      0.97       958
           7       0.95      0.98      0.97      1028
           8       0.97      0.96      0.96       974
           9       0.98      0.96      0.97      1009

    accuracy                           0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000

Tamaño de minilote=128

Loss: 0.12177726570870145
Accuracy: 0.9696999788284302

CONFUSION MATRIX
[[ 969    0    0    0    1    1    4    1    2    2]
 [   0 1121    1    3    0    2    4    1    2    1]
 [   6    3 1006    4    1    0    3    5    4    0]
 [   2    2    7  967    1    5    0    8    4   14]
 [   2    0    4    0  944    0   10    8    4   10]
 [   3    0    1   15    0  849    7    3    8    6]
 [   5    3    1    1    0    4  940    1    3    0]
 [   1    5   18    4    2    0    0  990    3    5]
 [   9    1    5    5    2    2    4    2  938    6]
 [   2    2    1    2   10    2    4   11    2  973]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.97      0.96      0.96      1010
           4       0.98      0.96      0.97       982
           5       0.98      0.95      0.97       892
           6       0.96      0.98      0.97       958
           7       0.96      0.96      0.96      1028
           8       0.97      0.96      0.97       974
           9       0.96      0.96      0.96      1009

    accuracy                           0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000

Tamaño de minilote=256

Loss: 0.10940445044689695
Accuracy: 0.9703999757766724

CONFUSION MATRIX
[[ 961    0    0    1    0    1    8    3    3    3]
 [   0 1124    3    0    0    1    3    1    1    2]
 [   5    3  994    3    5    0    3   17    2    0]
 [   1    0    5  977    0    9    0    8    6    4]
 [   1    0    3    0  944    1    3    6    1   23]
 [   3    0    0    8    2  853   12    3    4    7]
 [   3    2    0    0    5    3  941    0    4    0]
 [   1    4    7    1    1    0    0 1004    1    9]
 [   4    1    4   17    6    5    5    4  924    4]
 [   3    1    0    9    5    2    1    6    0  982]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.96      0.97      1032
           3       0.96      0.97      0.96      1010
           4       0.98      0.96      0.97       982
           5       0.97      0.96      0.97       892
           6       0.96      0.98      0.97       958
           7       0.95      0.98      0.97      1028
           8       0.98      0.95      0.96       974
           9       0.95      0.97      0.96      1009

    accuracy                           0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Experimento_3 epochs

Capas:
Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(10, activation='softmax')

Optimizador: Adam (lr=0.001)
Función de pérdida: 'categorical_crossentropy'
Métricas: 'accuracy' 

Tamaño de minilote=64
Set de validación de 0.3 de datos de entrenamiento

Resultados:

Épocas=50

Loss: 0.15498438150765256
Accuracy: 0.9729999899864197

CONFUSION MATRIX
[[ 964    0    1    1    0    8    3    1    2    0]
 [   0 1126    2    2    0    1    2    0    2    0]
 [   3    1 1013    0    2    1    2    6    3    1]
 [   0    4    9  975    0   11    1    5    3    2]
 [   1    0    2    0  941    0    5    4    1   28]
 [   2    0    0   10    1  860    4    2    5    8]
 [   3    2    0    1    6    6  936    0    4    0]
 [   0    5   13    3    0    0    0  992    2   13]
 [   1    1    8    8    4    3    3    5  938    3]
 [   3    2    0    5    3    3    0    6    2  985]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.99      0.98      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.98      0.97      1032
           3       0.97      0.97      0.97      1010
           4       0.98      0.96      0.97       982
           5       0.96      0.96      0.96       892
           6       0.98      0.98      0.98       958
           7       0.97      0.96      0.97      1028
           8       0.98      0.96      0.97       974
           9       0.95      0.98      0.96      1009

    accuracy                           0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000

Épocas = 100

Loss: 0.1779122782307902
Accuracy: 0.9745000004768372

CONFUSION MATRIX
[[ 964    1    4    1    1    1    4    2    1    1]
 [   0 1130    1    0    0    2    1    0    1    0]
 [   4    0 1000   11    2    0    1   10    4    0]
 [   0    0    3  995    0    4    0    3    4    1]
 [   0    1    3    0  938    0    7    4    5   24]
 [   2    0    1    9    1  867    3    2    3    4]
 [   4    4    3    1    1    8  933    0    4    0]
 [   1    4    8    5    1    0    1 1002    2    4]
 [   2    1    6   12    0    3    1    6  939    4]
 [   3    4    1    7    2    6    0    5    4  977]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.99      1.00      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.96      0.99      0.97      1010
           4       0.99      0.96      0.97       982
           5       0.97      0.97      0.97       892
           6       0.98      0.97      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.97      0.96      0.97       974
           9       0.96      0.97      0.97      1009

    accuracy                           0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Épocas=150

Loss: 0.24687271507636546
Accuracy: 0.9700999855995178

CONFUSION MATRIX
[[ 969    0    2    0    0    3    0    1    2    3]
 [   0 1123    2    2    0    2    4    0    2    0]
 [   4    1 1001    7    3    1    0   11    2    2]
 [   0    2    3  985    1    5    0    3    2    9]
 [   1    0    2    1  947    1    4    6    2   18]
 [   4    1    2   10    0  860    6    2    3    4]
 [   3    1    2    2    9    7  931    0    2    1]
 [   1    4    6    2    1    1    0 1009    0    4]
 [   4    3    6   18    2   12    3    8  912    6]
 [   1    5    0    7    9    7    0   13    3  964]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.97      0.97      1032
           3       0.95      0.98      0.96      1010
           4       0.97      0.96      0.97       982
           5       0.96      0.96      0.96       892
           6       0.98      0.97      0.98       958
           7       0.96      0.98      0.97      1028
           8       0.98      0.94      0.96       974
           9       0.95      0.96      0.95      1009

    accuracy                           0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Épocas=250

Loss: 0.31196128775970144
Accuracy: 0.9782999753952026

CONFUSION MATRIX
[[ 968    1    3    2    0    1    3    1    1    0]
 [   1 1126    1    2    0    0    3    0    2    0]
 [   3    0 1017    3    0    0    2    4    3    0]
 [   3    1    4  981    1    6    0    4    9    1]
 [   0    0    2    0  959    0    6    3    1   11]
 [   3    0    0   11    1  861    4    1    5    6]
 [   3    3    2    0    4    0  941    1    4    0]
 [   1    1    9    2    1    0    0 1003    0   11]
 [   1    1    4    6    2    2    1    6  948    3]
 [   1    3    0    5    9    4    0    7    1  979]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.99      0.98      1032
           3       0.97      0.97      0.97      1010
           4       0.98      0.98      0.98       982
           5       0.99      0.97      0.98       892
           6       0.98      0.98      0.98       958
           7       0.97      0.98      0.97      1028
           8       0.97      0.97      0.97       974
           9       0.97      0.97      0.97      1009

    accuracy                           0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Experimento_4 activation

Capas:
Dense(64, activation='sigmoid')
Dense(64, activation='sigmoid')
Dense(64, activation='sigmoid')
Dense(64, activation='sigmoid')
Dense(10, activation='softmax')

Optimizador: Adam (lr=0.001)
Función de pérdida: 'categorical_crossentropy'
Métricas: 'accuracy' 

Épocas=150
Tamaño de minilote=64
Set de validación de 0.3 de datos de entrenamiento

Resultados:

Loss: 0.1949544439264355
Accuracy: 0.9675999879837036

CONFUSION MATRIX
[[ 970    0    1    3    1    2    1    1    1    0]
 [   0 1123    5    0    0    0    3    1    3    0]
 [   3    3  997    7    7    0    3    4    7    1]
 [   0    1    8  974    0    7    0    5   12    3]
 [   2    0    1    1  955    1    7    2    3   10]
 [   7    0    0   14    0  841    8    2   15    5]
 [   4    3    3    0    9    4  931    0    4    0]
 [   0    7   18    3    7    1    0  978    1   13]
 [   2    1    8    4    3    2    1    2  949    2]
 [   3    6    1    6   14    4    0    3   14  958]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.98      0.99      0.99      1135
           2       0.96      0.97      0.96      1032
           3       0.96      0.96      0.96      1010
           4       0.96      0.97      0.97       982
           5       0.98      0.94      0.96       892
           6       0.98      0.97      0.97       958
           7       0.98      0.95      0.97      1028
           8       0.94      0.97      0.96       974
           9       0.97      0.95      0.96      1009

    accuracy                           0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Dense(64, activation='sigmoid')
Dense(64, activation='relu')
Dense(64, activation='sigmoid')
Dense(64, activation='relu')
Dense(10, activation='softmax')

Loss: 0.19317258006127366
Accuracy: 0.9764999747276306

CONFUSION MATRIX
[[ 967    1    2    0    1    2    4    1    1    1]
 [   0 1127    2    0    0    1    2    1    2    0]
 [   5    0 1012    1    1    0    2    7    3    1]
 [   0    3    7  988    0    3    0    4    3    2]
 [   1    0    3    0  961    0    6    2    1    8]
 [   8    0    0   11    0  858    4    2    4    5]
 [   3    3    1    1    6    3  939    0    2    0]
 [   1    2    9    3    1    0    0 1004    0    8]
 [   4    1    7    5    4    4    3    3  937    6]
 [   4    2    1    4    9    3    0    8    6  972]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.98      0.97      1032
           3       0.98      0.98      0.98      1010
           4       0.98      0.98      0.98       982
           5       0.98      0.96      0.97       892
           6       0.98      0.98      0.98       958
           7       0.97      0.98      0.97      1028
           8       0.98      0.96      0.97       974
           9       0.97      0.96      0.97      1009

    accuracy                           0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000

Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(64, activation='relu')
Dense(10, activation='softmax')

Loss: 0.18575592479631264
Accuracy: 0.9765999913215637

CONFUSION MATRIX
[[ 970    0    2    0    0    3    3    1    1    0]
 [   0 1127    0    4    0    0    2    1    1    0]
 [   5    2 1011    5    1    0    4    3    0    1]
 [   0    1    6  982    0    8    0    3    3    7]
 [   1    0    4    0  946    0   10    1    1   19]
 [   3    0    0    8    1  865    6    2    4    3]
 [   4    4    0    1    3    3  943    0    0    0]
 [   0    5   11    3    0    1    0 1001    0    7]
 [   3    1    8    2    2    4    5    6  940    3]
 [   1    3    0    5    6    4    2    3    4  981]]

CLASSIFICATION REPORT
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.98      0.97      1032
           3       0.97      0.97      0.97      1010
           4       0.99      0.96      0.97       982
           5       0.97      0.97      0.97       892
           6       0.97      0.98      0.98       958
           7       0.98      0.97      0.98      1028
           8       0.99      0.97      0.98       974
           9       0.96      0.97      0.97      1009

    accuracy                           0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


